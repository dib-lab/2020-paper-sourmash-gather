# Methods

## Revised theoretical analysis of FracMinHash

CTB: move this up, refer to it properly in the text.

Given two arbitrary sets $A$ and $B$ which are subsets of a domain
$\Omega$, the containment index $C(A,B)$ is defined as
$C(A,B):=\frac{\vert A \cap B \vert}{\vert A \vert}$. Let $h$ be a
perfect hash function $h~:~\Omega \rightarrow~[0,H]$ for some $H\in
\mathbb{R}$. For a *scale factor* $s$ where $0 \le s \le 1$, a
FracMinHash sketch of a set $A$ is defined as follows:

{% raw %}
```{=latex}
\begin{equation}
    %\mathbf{FRAC}_S(A) = \left\{\,h(a) \mid \forall a \in A\ {\rm s.t.}\ h(a) \leq Hs\right\}.
    \mathbf{FRAC}_S(A) = \left\{\,h(a) \mid \forall a \in A\ {\rm s.t.}\ h(a) \leq Hs\right\}.
\end{equation}
```
{% endraw %}

The scale factor $s$ is a tunable parameter that can modify the size of the sketch. Using this FracMinHash sketch, we define the FracMinHash estimate of the containment index $\hat{C}_\text{frac}(A,B)$ as follows:

{% raw %}
```{=latex}
\begin{equation}
    \hat{C}_\text{scale}(A,B):=\frac{\vert \mathbf{FRAC}_S(A) \cap \mathbf{FRAC}_S(B)\vert }{\vert \mathbf{FRAC}_S(A)\vert}.
\end{equation}
```
{% endraw %}

For notational simplicity, we define $X_A := \vert \mathbf{FRAC}_S(A)
\vert$. Observe that if one views $h$ as a uniformly distributed
random variable, we have that $X_A$ is distributed as a binomial
random variable: $X_A \sim {\rm Binom}(|A|, s)$. Furthermore, if
$A\cap B = \emptyset$ where both $A$ and $B$ are non-empty sets, then
$X_A$ and $X_B$ are independent when the probability of success is
strictly smaller than $1$. Using these notations, we compute the
expectation of (equation).

**Theorem 1:**
For $0<s<1$, if $A$ and $B$ are two distinct sets such that $A \cap B$ is non-empty,
{% raw %}
```{=latex}
\begin{align}
\mathrm{E}\left[\hat{C}_\text{frac}(A,B) \unicode{x1D7D9}_{\vert \mathbf{FRAC}_S(A) \vert>0} \right] =
\frac{\vert A\cap B \vert}{\vert A \vert} \left(1-(1-s)^{\vert A\vert}\right).
\end{align}
```
{% endraw %}


*Proof.* Using the notation introduced previously, observe that 

{% raw %}
```{=latex}
\begin{align}
\hat{C}_\text{frac}(A,B) \unicode{x1D7D9}_{\vert \mathbf{FRAC}_S(A) \vert>0} = \frac{X_{A\cap B}}{X_{A\cap B} + X_{A\setminus B}} \unicode{x1D7D9}_{X_{A\cap B} + X_{A\setminus B}>0},
\end{align}
```
{% endraw %}

and that the random variables $X_{A\cap B}$ and $X_{A\setminus B}$ are independent (which follows directly from the fact that $A \cap B$ is non-empty, and because $A$ and $B$ are distinct, $A \setminus B$ is also non-empty).
We will use the following fact from standard calculus:

{% raw %}
```{=latex}
\begin{align}
    \int_0^1 x t^{x+y-1}\, dt = \frac{x}{x+y} \unicode{x1D7D9}_{x+y>0}.
\end{align}
```
{% endraw %}

Then using the moment generating function of the binomial distribution, we have

{% raw %}
```{=latex}
\begin{align}
    \mathrm{E}\left[t^X_{A\cap B}\right] &= (1-s+st)^{\vert A \cap B \vert}\\
    \mathrm{E}\left[t^X_{A\setminus B}\right] &= (1-s+st)^{\vert A \setminus B \vert}
\end{align}
```
{% endraw %}

We also know by continuity that 
{% raw %}
```{=latex}
\begin{align}
    \mathrm{E}\left[X_{A\cap B} \, t^{X_{A\cap B}-1}\right] &= \frac{d}{dt} (1-s+st)^{\vert A \cap B \vert}\\
    &= \vert A\cap B \vert s (1-s+st)^{\vert A\cap B\vert-1}.
\end{align}
```
{% endraw %}

Using these observations, we can then finally calculate that 


{% raw %}
```{=latex}
\begin{align}
    \mathrm{E}\left[\frac{X_{A\cap B}}{X_{A\cap B} + X_{A\setminus B}} \unicode{x1D7D9}_{X_{A\cap B} + X_{A\setminus B}>0},\right] &= \mathrm{E}\left[\int_0^1 X_{A\cap B} \,  t^{X_{A\cap B}+X_{A\setminus B}-1}\,dt\right]\\
    &= \int_0^1 \mathrm{E}\left[X_{A\cap B}  \, t^{X_{A\cap B}+X_{A\setminus B}-1}\,dt\right]\label{line:1}\\
    &= \int_0^1 \mathrm{E}\left[X_{A\cap B}  \, t^{X_{A\cap B}-1}\right] \mathrm{E}\left[t^X_{A\setminus B}\right]\,dt\label{line:2}\\
    &= \vert A\cap B\vert \int_0^1(1-s+st)^{\vert A\cap B \vert + \vert A\setminus B \vert -1}\, dt\\
    &= \frac{\vert A \cap B\vert (1-s+st)^{\vert A \vert}}{\vert A \vert}\bigg\rvert_{t=0}^{t=1}\\
    &= \frac{\vert A\cap B \vert}{\vert A \vert} \left(1-(1-s)^{\vert A\vert}\right),
\end{align}
```
{% endraw %}

where Fubini's theorem is used in line 2 and independence in line 3.


In light of (theorem), we note that (equation) is *not* an
unbiased estimate of $C(A,B)$. This may explain the observations in
(Luiz thesis) that showed the uncorrected version in (eqn) leads to
suboptimal performance for short sequences (e.g viruses). However, for
sufficiently large $\vert A \vert$ and $s$, the bias factor
$\left(1-(1-s)^{\vert A\vert}\right)$ is sufficiently close to 1.

The expectation of $C_\text{frac}(A,B)$ follows directly from
(equation) and (theorem).

**Theorem 2:** For $0<s<1$, if $A$ and $B$ are two distinct
sets such that $A \cap B$ is non-empty, the expectation of $C_\text{frac}(A, B)$ is
given by

$$
\mathrm{E} [C_\text{frac}(A,B)] = \frac{\vert A\cap B \vert}{\vert A \vert}
$$

## Implementation of FracMinHash and min-set-cov

We provide implementations of FracMinHash and min-set-cov in the
software package `sourmash`, which is implemented in Python and Rust
and developed under the BSD license [@doi:10.21105/joss.00027] (cite
joss, zenodo latest version, github URL). FracMinHash sketches are
created for DNA sequence inputs using the `sourmash sketch dna`
command with the `scaled` parameter. Minimum metagenome covers are
generated using `sourmash gather` with the sketched metagenome as
query against a collection of one or more sketched genomes.

The results in this paper were generated with sourmash v4.2.X. (CTB:
create new release, generate zenodo doi.)

## Comparison between CMash, mash screen, and Scaled MinHash.

Experiments use $k=\{21, 31, 51\}$ (except for Mash, which only
supports $k \le 32$).  For Mash and CMash they were run with
$n=\{1000, 10000\}$ to evaluate the containment estimates when using
larger sketches with sizes comparable to the FracMinHash sketches
with $scaled=1000$.  The truth set is calculated using an exact
$k$-mer counter implemented with a _HashSet_ data structure in the
Rust programming language [@matsakis_rust_2014].

For _Mash Screen_ the ratio of hashes matched by total hashes is used
instead of the _Containment Score_, since the latter uses a $k$-mer
survival process modeled as a Poisson process first introduced in
[@fan_assembly_2015] and later used in the _Mash distance_
[@ondov_mash:_2016] and _Containment score_ [@ondov_mash_2019]
formulations.

## GenBank database sketching and searches

Minimum metagenome covers were calculated using a microbial genome
subset of GenBank (date XYZ, number of genomes ZZZ) using a scaled
factor of 2000 and a k-mer size of 31. Sketches for all genomes and
metagenomes were calculated with `sourmash sketch dna -p
scaled=2000,k=31`. The minimum metagenome covers were calculated using
all genomes sharing 100 hashes with the metagenome (that is, an
estimated overlap of 100,000 k-mers) with
`sourmash gather --threshold-bp 1e5`.
Overlapping sketches were saved with `--save-prefetch`
and matches were saved with `--save-matches`.

The GenBank database used is XYZ GB in size and is available for download
at ZZZ.

## Taxonomy

(I guess say what Luiz used, and then repeat this using sourmash taxonomy.)

## Read mapping and hybrid mapping pipeline

Metagenome reads were mapped to reference genomes using minimap2 v2.17
[@doi:10.1093/bioinformatics/bty191] with short single-end read mapping mode
(`-x sr`).

The complete workflow, from metagenome download to taxonomic analysis
and iterative mapping, is implemented in the genome-grist package
@url:https://github.com/dib-lab/genome-grist].  genome-grist uses
snakemake [@doi:10.12688/f1000research.29032.2] to define and execute
a workflow that combines sourmash sketching, metagenome cover
calculation, and taxonomic analysis with metagenome download from the
SRA, genome download from GenBank, and read mapping.  We used
genome-grist v0.7.3 (CTB: generate DOI!) to generate the results in
this paper (CTB: mention config file/put in paper data repo).

(CTB: Cite dependencies:

```
    - matplotlib>=3.4.3,<4
    - notebook>=6,<7
    - numpy>=1.21.3,<2
    - pandas>=1.3.4,<2
    - papermill>=2.1.2,<3
    - plotly>=4.9.0,<5
    - sourmash>=4.2.1,<5
  - bcftools=1.11
  - bedtools
  - bioconda
  - covtobed
  - minimap2=2.17
  - samtools=1.10
 - fastp=0.20.1
 - khmer=3.0.0a
 - lxml==4.6.1
 - pandas>1,<2
 - screed
 - seqtk=1.3
 - snakemake-minimal==6.6.1
 - sourmash>=4.2.1,<5
 - sra-tools=2.10.0
```

The hybrid selection and mapping pipeline using the rank-ordered min-set-cov
results was implemented in the `subtract_gather.py` script that is part
of the genome-grist package.

## Figures and notebooks for this paper.

(point at gather figures repo)

## Data accessions

The summary results from genome-grist for this paper are available HERE.

